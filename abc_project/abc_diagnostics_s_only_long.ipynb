{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bb8651",
   "metadata": {},
   "source": [
    "\n",
    "# ABC Diagnostics: Coverage, Residuals, and PPC (Early vs Late)\n",
    "\n",
    "This notebook loads a **pyABC** SQLite database, draws **posterior parameter samples** from the **last population**, re-simulates your ABM to compute **posterior predictive checks (PPC)**, and reports:\n",
    "\n",
    "- **Coverage** of the observed time series within 5–95% posterior predictive bands (per statistic; overall; early vs late windows).\n",
    "- **Residuals** (observed − posterior median) per statistic over time.\n",
    "- **Side‑by‑side PPC** panels for **early** and **late** windows.\n",
    "- A **discrepancy vs time** diagnostic (Euclidean distance between observed and posterior median across stats).\n",
    "- **Heuristic recommendations** for parameter/model changes based on late‑phase residual patterns.\n",
    "\n",
    "> **Requirements**: Run this in your project environment where `pyabc`, your ABM modules (`abm.clusters_model`, `abcp.compute_summary`, `abcp.abc_model_wrapper`), `numpy`, `pandas`, and `matplotlib` are installed.\n",
    "\n",
    "> **References (API we use):**\n",
    "> - `pyabc.storage.History`: querying posteriors, populations, distances; e.g., `History.get_distribution`, `History.get_all_populations` (pyABC docs).  \n",
    ">   See: https://pyabc.readthedocs.io/en/latest/api/pyabc.storage.html\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca64645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Optional: nicer style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "from pyabc import History  # pyABC data access\n",
    "\n",
    "# Project-specific imports (available in your environment)\n",
    "from abm.clusters_model import ClustersModel\n",
    "from abcp.compute_summary import simulate_timeseries\n",
    "from abcp.abc_model_wrapper import particle_to_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108416c",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Inputs\n",
    "Set the paths and options below. If your DB path is relative, **do not** prepend `sqlite:///`; the cell will construct the proper SQLAlchemy URI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- User inputs ---\n",
    "# Path to your pyABC SQLite DB (file produced by your run_abc_* scripts)\n",
    "db_path = \"results/abc_maxabs_Sonly.db\"  # <-- change this\n",
    "\n",
    "# Observed summary CSV used in calibration (must include 'timestep' and selected stats)\n",
    "observed_csv = \"observed/INV_ABM_ready_summary.csv\"  # <-- change this\n",
    "\n",
    "# Which statistics to analyze\n",
    "enable_gr = False  # set True if your observed CSV includes g(r) columns\n",
    "stats = [\"S0\", \"S1\", \"S2\"] if not enable_gr else [\"S0\", \"S1\", \"S2\", \"NND_med\", \"g_r40\", \"g_r80\"]\n",
    "\n",
    "# Time windows\n",
    "# Either give an explicit cutoff timestep (e.g., 50) or set to None and\n",
    "# a percentile-based split will be used (late = upper 40% by default)\n",
    "explicit_cut = None\n",
    "late_fraction = 0.4  # used if explicit_cut is None\n",
    "\n",
    "# Number of posterior samples to draw for PPC\n",
    "n_post_samples = 400\n",
    "\n",
    "# Model/simulation options\n",
    "motion = \"persistent\"   # same as calibration\n",
    "speed  = \"lognorm\"       # same as calibration\n",
    "seed_base = 12345        # base RNG seed for PPC simulations\n",
    "\n",
    "# Total steps and the exact timesteps to sample must match your calibration\n",
    "# (the observed CSV defines the set of timesteps)\n",
    "total_steps = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e252c6",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load observed data and pyABC history\n",
    "This uses `pyabc.storage.History` to connect to the database and `History.get_distribution()` to retrieve the **last population's weighted particles** (parameters and weights).  \n",
    "See the pyABC API docs for `History` and these query methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build SQLAlchemy URI for pyABC\n",
    "if db_path.startswith(\"sqlite://\"):\n",
    "    db_uri = db_path\n",
    "else:\n",
    "    db_uri = f\"sqlite:///{db_path}\"\n",
    "\n",
    "# Load history\n",
    "h = History(db_uri)\n",
    "run_id = h.id\n",
    "print(f\"Loaded DB: {db_uri} (run id={run_id})\")\n",
    "\n",
    "# Observed CSV\n",
    "obs_df = pd.read_csv(observed_csv).sort_values(\"timestep\").reset_index(drop=True)\n",
    "for s in [\"timestep\"] + stats:\n",
    "    if s not in obs_df.columns:\n",
    "        raise ValueError(f\"Observed CSV missing column: {s}\")\n",
    "\n",
    "# Timesteps and observed matrix\n",
    "timesteps = obs_df[\"timestep\"].astype(int).to_list()\n",
    "obs_mat = obs_df[stats].to_numpy(float)  # shape (T, K)\n",
    "T, K = obs_mat.shape\n",
    "\n",
    "# Early/late split\n",
    "if explicit_cut is not None:\n",
    "    cut = explicit_cut\n",
    "else:\n",
    "    # late starts at the (1 - late_fraction) quantile of timesteps\n",
    "    q = 1.0 - late_fraction\n",
    "    cut = int(np.quantile(timesteps, q))\n",
    "\n",
    "early_mask = (obs_df[\"timestep\"] <= cut).to_numpy()\n",
    "late_mask  = ~early_mask\n",
    "print(f\"Time split: early ≤ {cut}, late > {cut}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb6d4be",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Draw posterior parameter samples\n",
    "We query the **last population** via `History.get_distribution(m)` to obtain a DataFrame of parameter values and a corresponding weight vector. We then **resample** `n_post_samples` parameter sets according to those weights.\n",
    "\n",
    "> API reference: `History.get_distribution` (pyABC docs). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get last population's weighted parameters for model m=0\n",
    "params_df, weights = h.get_distribution(m=0)  # last population by default\n",
    "weights = np.asarray(weights, dtype=float)\n",
    "weights = weights / weights.sum()\n",
    "print(f\"Retrieved {len(params_df)} weighted particles from the last population.\")\n",
    "\n",
    "# Weighted resampling of parameter rows\n",
    "rng = np.random.default_rng(seed_base)\n",
    "idx = rng.choice(len(params_df), size=n_post_samples, replace=True, p=weights)\n",
    "post_samples = params_df.iloc[idx].reset_index(drop=True)\n",
    "post_samples.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a98550",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Posterior predictive simulations\n",
    "For each sampled parameter vector, we map to the model’s internal parameterization using your project’s `particle_to_params` helper, build a `ClustersModel` via a factory, and call `simulate_timeseries` at the observed timesteps. Each draw uses a distinct RNG seed for stochasticity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d10fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare a model factory with variable seed per draw\n",
    "\n",
    "def make_model(seed: int):\n",
    "    def factory(params_dict):\n",
    "        return ClustersModel(params=params_dict, seed=seed)\n",
    "    return factory\n",
    "\n",
    "# Run PPC simulations\n",
    "sim_cube = np.zeros((n_post_samples, T, K), dtype=float)\n",
    "\n",
    "for i in range(n_post_samples):\n",
    "    particle = post_samples.iloc[i].to_dict()\n",
    "    params = particle_to_params(particle, motion=motion, speed_dist=speed)\n",
    "    model_factory = make_model(seed_base + i)\n",
    "    sim_mat = simulate_timeseries(\n",
    "        model_factory,\n",
    "        params=params,\n",
    "        total_steps=total_steps,\n",
    "        sample_steps=tuple(timesteps),\n",
    "    )\n",
    "    # Align columns to `stats`\n",
    "    full_order = [\"S0\", \"S1\", \"S2\", \"NND_med\", \"g_r40\", \"g_r80\"]\n",
    "    col_idx = [full_order.index(s) for s in stats]\n",
    "    sim_sel = sim_mat[:, col_idx]\n",
    "    sim_cube[i] = sim_sel\n",
    "\n",
    "print(f\"Completed PPC: sim_cube shape = {sim_cube.shape} (samples x T x K)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2d5fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d198e5",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Summaries: quantiles, coverage, residuals, discrepancy\n",
    "- **Quantiles**: 5%, 50%, 95% per time point & statistic.\n",
    "- **Coverage**: fraction of time points where observed lies between 5% and 95%. Also reported separately for early and late windows.\n",
    "- **Residuals**: observed − posterior median per time point & statistic.\n",
    "- **Discrepancy vs time**: Euclidean distance between observed vector and posterior-median vector across stats at each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c878184",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lo = np.percentile(sim_cube, 5, axis=0)\n",
    "q_md = np.percentile(sim_cube, 50, axis=0)\n",
    "q_hi = np.percentile(sim_cube, 95, axis=0)\n",
    "\n",
    "# Coverage\n",
    "inside = (obs_mat >= q_lo) & (obs_mat <= q_hi)\n",
    "cov_overall = inside.mean(axis=0)  # per stat\n",
    "cov_early   = inside[early_mask].mean(axis=0)\n",
    "cov_late    = inside[late_mask].mean(axis=0)\n",
    "\n",
    "cov_df = pd.DataFrame({\n",
    "    'stat': stats,\n",
    "    'coverage_overall': cov_overall,\n",
    "    'coverage_early': cov_early,\n",
    "    'coverage_late': cov_late,\n",
    "})\n",
    "\n",
    "# Residuals (obs - posterior median)\n",
    "residuals = obs_mat - q_md  # T x K\n",
    "residuals_df = pd.DataFrame(residuals, columns=stats)\n",
    "residuals_df.insert(0, 'timestep', timesteps)\n",
    "\n",
    "# Euclidean discrepancy across stats per timepoint\n",
    "sq = (obs_mat - q_md) ** 2\n",
    "disc = np.sqrt(sq.sum(axis=1))\n",
    "\n",
    "print(\"Coverage (fraction of timepoints within 5-95 band) per stat:\")\n",
    "display(cov_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae50ad",
   "metadata": {},
   "source": [
    "\n",
    "## 6) PPC panels (early vs late)\n",
    "Each panel shows the **posterior median** (blue), **5–95% band** (blue fill), and the **observed** trajectory (black) over the respective window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def plot_ppc(ax, tmask, title_suffix):\n",
    "    t = np.array(timesteps)[tmask]\n",
    "    for k, s in enumerate(stats):\n",
    "        ax[k].fill_between(t, q_lo[tmask, k], q_hi[tmask, k], color='C0', alpha=0.2, label='5–95% band' if k==0 else None)\n",
    "        ax[k].plot(t, q_md[tmask, k], color='C0', lw=2, label='posterior median' if k==0 else None)\n",
    "        ax[k].plot(t, obs_mat[tmask, k], color='k', lw=1.5, label='observed' if k==0 else None)\n",
    "        ax[k].set_title(f\"{s} — {title_suffix}\")\n",
    "        ax[k].set_xlabel(\"timestep\")\n",
    "        ax[k].set_ylabel(s)\n",
    "    handles, labels = ax[0].get_legend_handles_labels()\n",
    "    if labels:\n",
    "        ax[0].legend(loc='best')\n",
    "\n",
    "fig, axes = plt.subplots(len(stats), 2, figsize=(14, 3*len(stats)), sharex=False)\n",
    "if len(stats) == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "plot_ppc(axes[:,0], early_mask, \"early\")\n",
    "plot_ppc(axes[:,1], late_mask,  \"late\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('ppc_init.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54116521",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Residuals per statistic (obs − posterior median)\n",
    "Positive residuals mean the **observed** is **above** the model’s predictive median; negative means the model’s median is above the observed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(len(stats), 1, figsize=(14, 3*len(stats)), sharex=True)\n",
    "if len(stats) == 1:\n",
    "    ax = [ax]\n",
    "\n",
    "for k, s in enumerate(stats):\n",
    "    ax[k].plot(timesteps, residuals[:, k], color='crimson', lw=1.8)\n",
    "    ax[k].axhline(0, color='k', lw=0.8)\n",
    "    ax[k].set_ylabel(f\"resid: {s}\")\n",
    "ax[-1].set_xlabel(\"timestep\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c51406",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Euclidean discrepancy vs time\n",
    "This is the Euclidean norm of residuals across the selected stats at each time point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(14, 3.2))\n",
    "ax.plot(timesteps, disc, color='firebrick', lw=2, label='median discrepancy')\n",
    "# 5–95% band across samples for the Euclidean discrepancy (optional, compute approx) \n",
    "# We'll approximate by using posterior quantiles of each stat and summing their squares is not exact for quantiles,\n",
    "# so we keep just the median curve here for robustness.\n",
    "ax.set_xlabel('timestep')\n",
    "ax.set_ylabel('Euclidean discrepancy')\n",
    "ax.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf35f8c",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Heuristic recommendations\n",
    "We generate suggestions automatically based on **late‑phase** residual patterns (median over late window):\n",
    "- If `S0` residual is **negative** (model median > observed): model depletes S0 **too slowly** → consider faster transitions/merging out of S0.\n",
    "- If `S1`/`S2` residuals are **positive** and large: model **under‑produces** these at late times → consider stronger adhesion/merging, density‑dependent acceleration, or heavier‑tailed speed/persistence.\n",
    "- If `NND_med` residual is **positive**: observed spacing > model → reduce aggregation / increase dispersal or heterogeneity.\n",
    "- If late coverage ≪ early coverage: consider **time‑weighted** distances or **piecewise** fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summaries for heuristic rules\n",
    "late_resid_mean = residuals[late_mask].mean(axis=0)  # per stat\n",
    "recos = []\n",
    "\n",
    "# Helper to fetch coverage\n",
    "cov_map = {row['stat']: row for _, row in cov_df.iterrows()}\n",
    "\n",
    "for k, s in enumerate(stats):\n",
    "    cov_e = float(cov_map[s]['coverage_early']) if s in cov_map else np.nan\n",
    "    cov_l = float(cov_map[s]['coverage_late'])  if s in cov_map else np.nan\n",
    "    recos.append({\n",
    "        'stat': s,\n",
    "        'late_residual_mean': float(late_resid_mean[k]),\n",
    "        'coverage_early': cov_e,\n",
    "        'coverage_late':  cov_l,\n",
    "    })\n",
    "\n",
    "reco_df = pd.DataFrame(recos)\n",
    "print(\"Late-window residual means and coverages:\")\n",
    "display(reco_df)\n",
    "\n",
    "# Textual recommendations\n",
    "messages = []\n",
    "\n",
    "# S0 too slow to decline\n",
    "if 'S0' in stats:\n",
    "    k = stats.index('S0')\n",
    "    if late_resid_mean[k] < -0.05 * max(1.0, np.nanmax(obs_mat[:,k])):  # scale-agnostic heuristic\n",
    "        messages.append(\"S0 declines too slowly relative to data: increase depletion/transition rate from S0; allow faster merging; consider time‑dependent or density‑dependent rate.\")\n",
    "\n",
    "# S1/S2 under-produced late\n",
    "for s in ['S1','S2']:\n",
    "    if s in stats:\n",
    "        k = stats.index(s)\n",
    "        if late_resid_mean[k] > 0.05 * max(1.0, np.nanmax(obs_mat[:,k])):\n",
    "            messages.append(f\"{s} under‑produced late: add/strengthen adhesion or merging kinetics; introduce density‑dependent acceleration; broaden speed/persistence distribution (heavier tail).\")\n",
    "\n",
    "# NND_med too small (model packs too much)\n",
    "if 'NND_med' in stats:\n",
    "    k = stats.index('NND_med')\n",
    "    if late_resid_mean[k] > 0.02 * max(1.0, np.nanmax(obs_mat[:,k])):\n",
    "        messages.append(\"NND_med lower than observed (model more compact): reduce aggregation strength; increase dispersal or heterogeneity in motion (e.g., wider log-normal speed/persistence).\")\n",
    "\n",
    "# Coverage deterioration\n",
    "if (cov_df['coverage_late'].mean() + 1e-12) < (cov_df['coverage_early'].mean() - 0.15):\n",
    "    messages.append(\"Coverage drops substantially in late phase: use time‑weighted or windowed distances (e.g., higher weight after the split); try a two‑stage fit.\")\n",
    "\n",
    "print(\"Suggested actions (heuristic):\")\n",
    "if messages:\n",
    "    for i, m in enumerate(messages, 1):\n",
    "        print(f\"{i}. {m}\")\n",
    "else:\n",
    "    print(\"No strong systematic late‑phase bias detected by the heuristics.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821f07a",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Save key artifacts\n",
    "This cell saves coverage and residuals tables to `results/` for reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Path('results').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "cov_out = Path('results/diagnostics_coverage.csv')\n",
    "resid_out = Path('results/diagnostics_residuals.csv')\n",
    "\n",
    "cov_df.to_csv(cov_out, index=False)\n",
    "residuals_df.to_csv(resid_out, index=False)\n",
    "\n",
    "print(f\"Saved: {cov_out} Saved: {resid_out}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesa_abm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
